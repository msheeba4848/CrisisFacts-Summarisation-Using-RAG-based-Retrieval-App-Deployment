{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "BGWrhGCIEC9U"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df=pd.read_csv(\"all_data_cleaned.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rank_bm25 torch torchvision transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BQYkR_UEc7V",
        "outputId": "29fe86b6-e609-4900-9d6a-cc685217b462"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rank_bm25 in /usr/local/lib/python3.10/dist-packages (0.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rank_bm25) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['cleaned_text'].head())  # Check the first few rows\n",
        "print(df['cleaned_text'].dtype)  # Ensure it's a string type\n",
        "print(df['cleaned_text'].isnull().sum())  # Check for missing values\n",
        "df['cleaned_text'] = df['cleaned_text'].fillna(\"\").astype(str)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eP_gjWl2FVh3",
        "outputId": "ef6ebb54-4f4e-4541-992e-cfb33ff0023a"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    approximately 100km long firebreaks have been ...\n",
            "1                                        god bless you\n",
            "2    rt cracked wine casks damaged historical build...\n",
            "3    im really just excited for new undies and pink...\n",
            "4    rescue effort expands in india pakistan as flo...\n",
            "Name: cleaned_text, dtype: object\n",
            "object\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")"
      ],
      "metadata": {
        "id": "w3dno-2tPsuj"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This part remains the same as your code, where embeddings are computed for semantic similarity-based retrieval:\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def compute_embeddings_batchwise(texts, batch_size=32):\n",
        "    \"\"\"Compute dense embeddings in batches to avoid memory issues.\"\"\"\n",
        "    embeddings = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i + batch_size]\n",
        "        inputs = tokenizer(batch_texts, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        batch_embeddings = outputs.last_hidden_state[:, 0, :].numpy()\n",
        "        embeddings.append(batch_embeddings)\n",
        "    return np.vstack(embeddings)\n",
        "\n",
        "# Compute embeddings\n",
        "texts = df['cleaned_text'].fillna(\"\").tolist()\n",
        "embeddings = compute_embeddings_batchwise(texts)\n",
        "\n",
        "# Save embeddings to a file\n",
        "np.save(\"embeddings.npy\", embeddings)  # Save as .npy file\n",
        "print(\"Embeddings saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "33y06lDQESn7",
        "outputId": "21332b40-f55b-4fe3-9028-a068a48d5302"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-154-0f393a2149f5>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Compute embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleaned_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_embeddings_batchwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Save embeddings to a file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-154-0f393a2149f5>\u001b[0m in \u001b[0;36mcompute_embeddings_batchwise\u001b[0;34m(texts, batch_size)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mbatch_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    796\u001b[0m                 )\n\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m         return self.transformer(\n\u001b[0m\u001b[1;32m    799\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    549\u001b[0m                 )\n\u001b[1;32m    550\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    552\u001b[0m                     \u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m                     \u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \"\"\"\n\u001b[1;32m    476\u001b[0m         \u001b[0;31m# Self-Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         sa_output = self.attention(\n\u001b[0m\u001b[1;32m    478\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_lin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load precomputed embeddings\n",
        "embeddings = np.load(\"embeddings.npy\")\n",
        "print(\"Embeddings loaded successfully!\")\n",
        "print(f\"Shape of embeddings: {embeddings.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pd0A88qN8ZcB",
        "outputId": "b489cb4e-9315-49f7-adb3-d0f20deeab73"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings loaded successfully!\n",
            "Shape of embeddings: (212766, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rank_bm25 import BM25Okapi\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Tokenize the corpus for BM25\n",
        "tokenized_corpus = [text.split() for text in df['cleaned_text'].fillna(\"\")]\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "def retrieve_top_events(query, bm25, embeddings, df, top_k=5, alpha=0.5):\n",
        "    \"\"\"\n",
        "    Retrieve top-k events combining BM25 and Dense Embedding scores.\n",
        "\n",
        "    Parameters:\n",
        "    - query (str): Query text.\n",
        "    - bm25 (BM25Okapi): BM25 model.\n",
        "    - embeddings (ndarray): Dense embeddings for documents.\n",
        "    - df (DataFrame): DataFrame containing the dataset.\n",
        "    - top_k (int): Number of top results to retrieve.\n",
        "    - alpha (float): Weight for BM25 scores.\n",
        "\n",
        "    Returns:\n",
        "    - List of top-k events ranked by relevance.\n",
        "    \"\"\"\n",
        "    # Step 1: BM25 retrieval\n",
        "    tokenized_query = query.split()\n",
        "    bm25_scores = bm25.get_scores(tokenized_query)\n",
        "    bm25_scores = bm25_scores / np.max(bm25_scores)  # Normalize BM25 scores\n",
        "\n",
        "    # Step 2: Dense retrieval\n",
        "    query_embedding = compute_query_embedding(query)\n",
        "    dense_scores = cosine_similarity(query_embedding, embeddings).flatten()\n",
        "    dense_scores = dense_scores / np.max(dense_scores)  # Normalize Dense scores\n",
        "\n",
        "    # Step 3: Combine BM25 and Dense scores\n",
        "    combined_scores = alpha * bm25_scores + (1 - alpha) * dense_scores\n",
        "\n",
        "    # Step 4: Rank and retrieve top-k events\n",
        "    top_indices = np.argsort(combined_scores)[::-1][:top_k]\n",
        "    top_events = df.iloc[top_indices]['event'].unique()\n",
        "    return top_events\n"
      ],
      "metadata": {
        "id": "WTy579_QESsQ"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_by_class_label(df, event, class_label):\n",
        "    \"\"\"Filter rows by event and class label.\"\"\"\n",
        "    return df[(df['event'] == event) & (df['class_label'].str.contains(class_label, case=False, na=False))]\n"
      ],
      "metadata": {
        "id": "N07kPJVt-Xlq"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Remove unnecessary tokens, URLs, and mentions from text.\"\"\"\n",
        "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
        "    text = re.sub(r'@\\w+', '', text)  # Remove mentions\n",
        "    text = re.sub(r'rt ', '', text, flags=re.IGNORECASE)  # Remove \"RT\" for retweets\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove special characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "def summarize_top_relevant_texts(results, max_rows=3):\n",
        "    \"\"\"\n",
        "    Summarize the top N most relevant rows, dynamically adjusting max_length.\n",
        "    \"\"\"\n",
        "    top_texts = \" \".join(clean_text(text) for text in results['cleaned_text'].head(max_rows))\n",
        "    input_length = len(top_texts.split())\n",
        "    max_length = min(100, input_length - 10)  # Dynamically adjust max_length\n",
        "    min_length = min(30, max_length // 2)  # Adjust min_length proportionally\n",
        "\n",
        "    try:\n",
        "        summary = summarizer(top_texts, max_length=max_length, min_length=min_length, do_sample=False)\n",
        "        return summary[0]['summary_text']\n",
        "    except Exception as e:\n",
        "        return f\"Error during summarization: {e}\"\n",
        "\n"
      ],
      "metadata": {
        "id": "dV8pkR05IBY6"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load the summarizer\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "def summarize_texts(filtered_df, max_length=100, min_length=30):\n",
        "    \"\"\"Summarize filtered texts.\"\"\"\n",
        "    combined_text = \" \".join(filtered_df['cleaned_text'].tolist())\n",
        "    combined_text = combined_text[:2000]  # Truncate for summarization\n",
        "    try:\n",
        "        summary = summarizer(combined_text, max_length=max_length, min_length=min_length, do_sample=False)\n",
        "        return summary[0]['summary_text']\n",
        "    except Exception as e:\n",
        "        return f\"Error during summarization: {e}\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mho4q81M4hMf",
        "outputId": "43f0511a-9118-4f54-c026-bb0dc283bd23"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def interactive_hybrid_summarization(df, bm25, embeddings):\n",
        "    print(\"Welcome to the summarization system!\")\n",
        "    query = input(\"What event are you interested in? (e.g., 'earthquake relief', 'hurricane rescue')\\n> \").strip()\n",
        "\n",
        "    # Step 1: Retrieve top events using BM25 + Dense Retrieval\n",
        "    top_events = retrieve_top_events(query, bm25, embeddings, df, top_k=5, alpha=0.5)\n",
        "    print(\"\\nTop events related to your query:\")\n",
        "    for idx, event in enumerate(top_events, 1):\n",
        "        print(f\"{idx}. {event}\")\n",
        "\n",
        "    event_idx = int(input(\"\\nSelect the number corresponding to your event: \").strip()) - 1\n",
        "    selected_event = top_events[event_idx]\n",
        "    print(f\"\\nYou selected: {selected_event}\")\n",
        "\n",
        "    # Step 2: Retrieve available class labels for the selected event\n",
        "    available_labels = df[df['event'] == selected_event]['class_label'].unique()\n",
        "    print(\"\\nWhat label are you interested in? Here are the available options:\")\n",
        "    for idx, label in enumerate(available_labels, 1):\n",
        "        print(f\"{idx}. {label}\")\n",
        "\n",
        "    label_idx = int(input(\"\\nSelect the number corresponding to your label: \").strip()) - 1\n",
        "    selected_label = available_labels[label_idx]\n",
        "    print(f\"\\nYou selected: {selected_label}\")\n",
        "\n",
        "    # Step 3: Filter rows based on event and class label\n",
        "    filtered_df = filter_by_class_label(df, selected_event, selected_label)\n",
        "    if not filtered_df.empty:\n",
        "        print(\"\\nGenerating summary...\")\n",
        "        summary = summarize_texts(filtered_df)\n",
        "        print(f\"\\nSummary for '{selected_event}' and label '{selected_label}':\\n{summary}\")\n",
        "    else:\n",
        "        print(f\"No relevant data found for event: '{selected_event}' and label: '{selected_label}'.\")\n"
      ],
      "metadata": {
        "id": "sFcxipzO4hSR"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_relevant_rows(results, query):\n",
        "    \"\"\"\n",
        "    Filter rows that are directly relevant to the query.\n",
        "    Prioritize `event` matches, then `class_label`, and finally text-based matches.\n",
        "    \"\"\"\n",
        "    normalized_query = escape_special_chars(query.lower().replace(' ', '_'))\n",
        "    event_matches = results[results['event'].str.contains(normalized_query, case=False, na=False)]\n",
        "    if not event_matches.empty:\n",
        "        return event_matches  # Return rows with event matches\n",
        "\n",
        "    # Fall back to class_label and text matches if no event matches\n",
        "    text_matches = results[\n",
        "        results['cleaned_text'].str.contains('|'.join(normalized_query.split('_')), case=False, na=False)\n",
        "    ]\n",
        "    return text_matches\n",
        "\n"
      ],
      "metadata": {
        "id": "b33aHsw1FEW2"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def escape_special_chars(text):\n",
        "    \"\"\"Escape special characters for regex matching.\"\"\"\n",
        "    return re.escape(text)\n",
        "\n",
        "def filter_relevant_rows(results, query):\n",
        "    \"\"\"\n",
        "    Filter rows for relevance by prioritizing event matches.\n",
        "    \"\"\"\n",
        "    normalized_query = escape_special_chars(query)\n",
        "    # Exact match with `event` column\n",
        "    event_matches = results[results['event'].str.contains(normalized_query, case=False, na=False)]\n",
        "    if not event_matches.empty:\n",
        "        return event_matches\n",
        "\n",
        "    # Fallback to broader text-based relevance\n",
        "    text_matches = results[\n",
        "        results['cleaned_text'].str.contains('|'.join(normalized_query.split('_')), case=False, na=False)\n",
        "    ]\n",
        "    return text_matches\n",
        "\n"
      ],
      "metadata": {
        "id": "l2DPpnJ2Jkus"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_query_summary(df, bm25, embeddings, query, alpha=0.5, top_k=10):\n",
        "    \"\"\"\n",
        "    Generate a summary for a custom query by searching across all events and class labels.\n",
        "    \"\"\"\n",
        "    # Normalize the query\n",
        "    normalized_query = normalize_query(query)\n",
        "\n",
        "    # Step 1: BM25 scores\n",
        "    tokenized_query = normalized_query.split()\n",
        "    bm25_scores = bm25.get_scores(tokenized_query)\n",
        "    bm25_scores = bm25_scores / np.max(bm25_scores) if np.max(bm25_scores) > 0 else bm25_scores  # Normalize BM25 scores\n",
        "\n",
        "    # Step 2: Dense scores\n",
        "    query_embedding = compute_query_embedding(query)\n",
        "    dense_scores = cosine_similarity(query_embedding, embeddings).flatten()\n",
        "    dense_scores = dense_scores / np.max(dense_scores) if np.max(dense_scores) > 0 else dense_scores  # Normalize Dense scores\n",
        "\n",
        "    # Step 3: Combine scores\n",
        "    combined_scores = alpha * bm25_scores + (1 - alpha) * dense_scores\n",
        "    top_indices = np.argsort(combined_scores)[::-1][:top_k]\n",
        "\n",
        "    # Step 4: Retrieve top rows\n",
        "    top_results = df.iloc[top_indices]\n",
        "    print(f\"\\nTop results based on BM25 and dense scores:\")\n",
        "    print(top_results[['event', 'class_label', 'cleaned_text']].head(5))\n",
        "\n",
        "    # Step 5: Filter for relevant rows\n",
        "    filtered_results = filter_relevant_rows(top_results, normalized_query)\n",
        "\n",
        "    if not filtered_results.empty:\n",
        "        print(f\"\\nFiltered relevant rows for query '{query}':\")\n",
        "        print(filtered_results[['event', 'class_label', 'cleaned_text']].head(5))\n",
        "        summary = summarize_top_relevant_texts(filtered_results, max_rows=3)\n",
        "        return summary\n",
        "    else:\n",
        "        # Fallback: Match directly with the event column\n",
        "        matched_event_rows = df[df['event'].str.contains(escape_special_chars(normalized_query), case=False, na=False)]\n",
        "        if not matched_event_rows.empty:\n",
        "            print(f\"\\nRows found for event match '{query}':\")\n",
        "            print(matched_event_rows[['event', 'class_label', 'cleaned_text']].head(5))\n",
        "            summary = summarize_top_relevant_texts(matched_event_rows, max_rows=3)\n",
        "            return summary\n",
        "        else:\n",
        "            return f\"No relevant data found for query: '{query}'.\"\n"
      ],
      "metadata": {
        "id": "b1XbMFZs9wYT"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def humanize_labels(label):\n",
        "    \"\"\"Convert snake_case class labels to human-readable format.\"\"\"\n",
        "    return label.replace('_', ' ').title()\n",
        "\n",
        "def humanize_events(event):\n",
        "    \"\"\"Convert snake_case events to human-readable format with specific disaster handling.\"\"\"\n",
        "    event = event.replace('_earthquake', ' Earthquake')\n",
        "    event = event.replace('_hurricane', ' Hurricane')\n",
        "    event = event.replace('_floods', ' Floods')\n",
        "    event = event.replace('_typhoon', ' Typhoon')\n",
        "    event = event.replace('_cyclone', ' Cyclone')\n",
        "    event = event.replace('_bombings', ' Bombings')\n",
        "    event = event.replace('_explosion', ' Explosion')\n",
        "    event = event.replace('_train-crash', ' Train Crash')\n",
        "    event = event.replace('_wildfires', ' Wildfires')\n",
        "    event = event.replace('_volcano', ' Volcano')\n",
        "    event = event.replace('_shootings', ' Shootings')\n",
        "    event = event.replace('_syndrome', ' Syndrome')\n",
        "    event = event.replace('_fire', ' Fire')\n",
        "    event = event.replace('_building-collapse', ' Building Collapse')\n",
        "    event = event.replace('_airport', ' Airport')\n",
        "    event = event.replace('_refinery-explosion', ' Refinery Explosion')\n",
        "    event = event.replace('_respiratory', ' Respiratory')\n",
        "    event = event.replace('_', ' ').title()  # Convert remaining snake_case to Title Case\n",
        "    return event\n",
        "\n",
        "\n",
        "\n",
        "def normalize_input(user_input):\n",
        "    \"\"\"Normalize user input to match dataset format.\"\"\"\n",
        "    return user_input.lower().replace(' ', '_')\n",
        "\n",
        "\n",
        "def normalize_query(query):\n",
        "    \"\"\"Normalize the query to match the dataset format.\"\"\"\n",
        "    # Define filler words and phrases to remove\n",
        "    fillers = [\n",
        "        \"what about \", \"tell me about \", \"show me \", \"can you find \",\n",
        "        \"could you find \", \"is there any \", \"do you have \", \"please find \",\n",
        "        \"any information on \", \"anything about \", \"how about \",\n",
        "        \"do you know \", \"can I see \", \"give me details on\", \"can you find information about\",\n",
        "        \"what does\"\n",
        "    ]\n",
        "\n",
        "    # Remove filler words\n",
        "    query = query.lower()\n",
        "    for filler in fillers:\n",
        "        query = query.replace(filler, \"\")\n",
        "\n",
        "    # Remove multiple question marks and extra spaces\n",
        "    query = query.replace(\"?\", \"\").strip()\n",
        "    query = query.replace(\"????\", \"\").strip()\n",
        "    query = query.replace(\"!\", \"\").strip()\n",
        "    # Replace spaces with underscores\n",
        "    query = query.replace(\" \", \"_\")\n",
        "\n",
        "    return query\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xZ4rYpaM_jLq"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "events = [\n",
        "    '2015_nepal_earthquake', '2014_california_earthquake', '2013_boston_bombings-ontopic',\n",
        "    '2014_pakistan_floods', '2014_chile_earthquake', '2014_philippines_typhoon-hagupit',\n",
        "    '2012_sandy_hurricane-ontopic', '2013_west_texas', 'hurricane_irma', 'hurricane_maria',\n",
        "    '2013_queensland_floods-ontopic', '2013_pakistan_earthquake', 'hurricane_harvey',\n",
        "    '2014-2015_worldwide_landslides', '2013_alberta_floods', '2013_oklahoma_tornado-ontopic',\n",
        "    '2013_alberta_floods-ontopic', '2015_vanuatu_cyclone', '2013_colorado_floods',\n",
        "    '2013_australia_bushfire', '2014_india_floods', '2013_ny_train-crash', 'srilanka_floods',\n",
        "    '2012_philipinnes_floods', '2014_mexico_hurricane-odile', '2013_glasgow_helicopter-crash',\n",
        "    '2011_joplin_tornado-a121571', '2013_bangladesh_savar-building-collapse',\n",
        "    '2013_brazil_nightclub-fire', 'mexico_earthquake', '2013_manila_floods',\n",
        "    '2013_phillipines_typhoon-yolanda', '2013_singapore_haze', '2013_russia_meteor_en-mixed',\n",
        "    '2014_iceland_volcano', 'iraq_iran_earthquake', '2013_queensland_floods',\n",
        "    '2013_canada_lac-megantic-train-crash', '2012_philippines_typhoon-pablo',\n",
        "    'california_wildfires', '2015_vanuatu_cyclone-pam', '2012_us_sandy-hurricane-a143145',\n",
        "    '2014_philippines_typhoon', '2013_bohol_earthquake', '2013_west-texas_explosion',\n",
        "    '2012_costa-rica_earthquake', '2013_spain_train-crash_en-mixed', '2013_boston_bombings',\n",
        "    '2012_colorado_wildfires', '2014_worldwide_ebola', '2013_la_airport-shootings',\n",
        "    '2012_us_sandy-hurricane-a144267', '2011_joplin_tornado-a131709', '2014_malaysia_airline',\n",
        "    '2012_venezuela_refinery-explosion', '2012_guatemala_earthquake',\n",
        "    '2014_middle-east_respiratory-syndrome', '2013_italy_sardinia', '2012_italy_earthquakes',\n",
        "    '2014_chile_earthquake_esp'\n",
        "]\n",
        "\n",
        "human_readable_events = [humanize_events(event) for event in events]\n",
        "print(human_readable_events)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtCrrjpHBaM-",
        "outputId": "3b5ff167-4368-441a-d681-619963834d34"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['2015 Nepal Earthquake', '2014 California Earthquake', '2013 Boston Bombings-Ontopic', '2014 Pakistan Floods', '2014 Chile Earthquake', '2014 Philippines Typhoon-Hagupit', '2012 Sandy Hurricane-Ontopic', '2013 West Texas', 'Hurricane Irma', 'Hurricane Maria', '2013 Queensland Floods-Ontopic', '2013 Pakistan Earthquake', 'Hurricane Harvey', '2014-2015 Worldwide Landslides', '2013 Alberta Floods', '2013 Oklahoma Tornado-Ontopic', '2013 Alberta Floods-Ontopic', '2015 Vanuatu Cyclone', '2013 Colorado Floods', '2013 Australia Bushfire', '2014 India Floods', '2013 Ny Train Crash', 'Srilanka Floods', '2012 Philipinnes Floods', '2014 Mexico Hurricane-Odile', '2013 Glasgow Helicopter-Crash', '2011 Joplin Tornado-A121571', '2013 Bangladesh Savar-Building-Collapse', '2013 Brazil Nightclub-Fire', 'Mexico Earthquake', '2013 Manila Floods', '2013 Phillipines Typhoon-Yolanda', '2013 Singapore Haze', '2013 Russia Meteor En-Mixed', '2014 Iceland Volcano', 'Iraq Iran Earthquake', '2013 Queensland Floods', '2013 Canada Lac-Megantic-Train-Crash', '2012 Philippines Typhoon-Pablo', 'California Wildfires', '2015 Vanuatu Cyclone-Pam', '2012 Us Sandy-Hurricane-A143145', '2014 Philippines Typhoon', '2013 Bohol Earthquake', '2013 West-Texas Explosion', '2012 Costa-Rica Earthquake', '2013 Spain Train Crash En-Mixed', '2013 Boston Bombings', '2012 Colorado Wildfires', '2014 Worldwide Ebola', '2013 La Airport-Shootings', '2012 Us Sandy-Hurricane-A144267', '2011 Joplin Tornado-A131709', '2014 Malaysia Airline', '2012 Venezuela Refinery Explosion', '2012 Guatemala Earthquake', '2014 Middle-East Respiratory-Syndrome', '2013 Italy Sardinia', '2012 Italy Earthquakes', '2014 Chile Earthquake Esp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Original class labels\n",
        "class_labels = [\n",
        "    'infrastructure_and_utilities_damage', 'not_humanitarian', 'injured_or_dead_people',\n",
        "    'sympathy_and_support', 'donation_and_volunteering', 'response_efforts',\n",
        "    'caution_and_advice', 'requests_or_needs', 'affected_individual',\n",
        "    'displaced_and_evacuations', 'missing_and_found_people', 'not_informative',\n",
        "    'informative'\n",
        "]\n",
        "\n",
        "# Transform class labels\n",
        "human_readable_labels = [humanize_labels(label) for label in class_labels]\n",
        "print(human_readable_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBrFdWqmBtlN",
        "outputId": "18ea9965-3402-4507-e0ad-a559e88754c2"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Infrastructure And Utilities Damage', 'Not Humanitarian', 'Injured Or Dead People', 'Sympathy And Support', 'Donation And Volunteering', 'Response Efforts', 'Caution And Advice', 'Requests Or Needs', 'Affected Individual', 'Displaced And Evacuations', 'Missing And Found People', 'Not Informative', 'Informative']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def interactive_hybrid_summarization_with_improvements(df, bm25, embeddings):\n",
        "    print(\"Welcome to the summarization system!\")\n",
        "    print(\"\\nOptions:\")\n",
        "    print(\"1. Summarize based on specific event and class label\")\n",
        "    print(\"2. Generate a summary for a custom query across the dataset\")\n",
        "\n",
        "    option = input(\"Choose an option (1 or 2): \").strip()\n",
        "\n",
        "    if option == \"1\":\n",
        "        query = input(\"What event are you interested in? (e.g., 'earthquake relief', 'hurricane rescue')\\n> \").strip()\n",
        "        normalized_query = normalize_input(query)\n",
        "        top_events = retrieve_top_events(normalized_query, bm25, embeddings, df, top_k=5, alpha=0.5)\n",
        "\n",
        "        # Display human-readable events\n",
        "        print(\"\\nTop events related to your query:\")\n",
        "        human_readable_events = [humanize_events(event) for event in top_events]\n",
        "        for idx, event in enumerate(human_readable_events, 1):\n",
        "            print(f\"{idx}. {event}\")\n",
        "        try:\n",
        "            event_idx = int(input(\"\\nSelect the number corresponding to your event: \").strip()) - 1\n",
        "            if event_idx < 0 or event_idx >= len(top_events):\n",
        "                raise ValueError(\"Invalid selection. Please choose a valid number.\")\n",
        "        except ValueError as e:\n",
        "            print(e)\n",
        "            return\n",
        "        selected_event = top_events[event_idx]\n",
        "        print(f\"\\nYou selected: {humanize_events(selected_event)}\")\n",
        "\n",
        "        # Retrieve available class labels\n",
        "        available_labels = df[df['event'] == selected_event]['class_label'].unique()\n",
        "        human_readable_labels = [humanize_labels(label) for label in available_labels]\n",
        "        print(\"\\nWhat label are you interested in? Here are the available options:\")\n",
        "        for idx, label in enumerate(human_readable_labels, 1):\n",
        "            print(f\"{idx}. {label}\")\n",
        "        try:\n",
        "            label_idx = int(input(\"\\nSelect the number corresponding to your label: \").strip()) - 1\n",
        "            if label_idx < 0 or label_idx >= len(available_labels):\n",
        "                raise ValueError(\"Invalid selection. Please choose a valid number.\")\n",
        "        except ValueError as e:\n",
        "            print(e)\n",
        "            return\n",
        "        selected_label = available_labels[label_idx]\n",
        "        print(f\"\\nYou selected: {humanize_labels(selected_label)}\")\n",
        "\n",
        "        # Summarize and save\n",
        "        filtered_df = filter_by_class_label(df, selected_event, selected_label)\n",
        "        if not filtered_df.empty:\n",
        "            print(\"\\nGenerating summary...\")\n",
        "            summary = summarize_texts(filtered_df)\n",
        "            print(f\"\\nSummary for '{humanize_events(selected_event)}' and label '{humanize_labels(selected_label)}':\\n{summary}\")\n",
        "            save_option = input(\"\\nWould you like to save this summary? (yes/no): \").strip().lower()\n",
        "            if save_option == \"yes\":\n",
        "                save_summary(humanize_events(selected_event), humanize_labels(selected_label), summary)\n",
        "        else:\n",
        "            print(f\"No relevant data found for event: '{humanize_events(selected_event)}' and label: '{humanize_labels(selected_label)}'.\")\n",
        "\n",
        "    elif option == \"2\":\n",
        "        query = input(\"Enter your custom query (e.g., 'earthquake damage'):\\n> \").strip()\n",
        "        normalized_query = normalize_input(query)\n",
        "        summary = custom_query_summary(df, bm25, embeddings, normalized_query, alpha=0.5, top_k=10)\n",
        "        print(f\"\\nSummary for custom query '{query}':\\n{summary}\")\n",
        "    else:\n",
        "        print(\"Invalid option. Please restart the system.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "uqUPzW8jBsJA"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_texts(filtered_df, max_length=100, min_length=30):\n",
        "    combined_text = \" \".join(filtered_df['cleaned_text'].tolist())\n",
        "    if len(combined_text) > 2000:  # Truncate if too long\n",
        "        combined_text = combined_text[:2000]\n",
        "    try:\n",
        "        summary = summarizer(combined_text, max_length=max_length, min_length=min_length, do_sample=False)\n",
        "        return summary[0]['summary_text']\n",
        "    except Exception as e:\n",
        "        return f\"Error during summarization: {e}\"\n",
        "\n",
        "def save_summary(event, label, summary):\n",
        "    \"\"\"Save the generated summary to a file.\"\"\"\n",
        "    filename = f\"summary_{event.replace(' ', '_')}_{label.replace(' ', '_')}.txt\"\n",
        "    with open(filename, \"w\") as file:\n",
        "        file.write(f\"Event: {event}\\n\")\n",
        "        file.write(f\"Label: {label}\\n\")\n",
        "        file.write(f\"Summary:\\n{summary}\")\n",
        "    print(f\"Summary saved to {filename}.\")"
      ],
      "metadata": {
        "id": "yU2d1j2lD-Fs"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure BM25 and embeddings are initialized\n",
        "interactive_hybrid_summarization_with_improvements(df, bm25, embeddings)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ou1z3pL4_0hu",
        "outputId": "ad079eb1-1ae9-465f-a7dd-30fd1b6a6e9a"
      },
      "execution_count": 203,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to the summarization system!\n",
            "\n",
            "Options:\n",
            "1. Summarize based on specific event and class label\n",
            "2. Generate a summary for a custom query across the dataset\n",
            "Choose an option (1 or 2): 1\n",
            "What event are you interested in? (e.g., 'earthquake relief', 'hurricane rescue')\n",
            "> earthquake relief\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-190-c4f0009dd79a>:27: RuntimeWarning: invalid value encountered in divide\n",
            "  bm25_scores = bm25_scores / np.max(bm25_scores)  # Normalize BM25 scores\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top events related to your query:\n",
            "1. 2015 Vanuatu Cyclone\n",
            "2. 2013 Alberta Floods-Ontopic\n",
            "3. 2013 Oklahoma Tornado-Ontopic\n",
            "4. 2015 Nepal Earthquake\n",
            "5. 2013 West Texas\n",
            "\n",
            "Select the number corresponding to your event: 5\n",
            "\n",
            "You selected: 2013 West Texas\n",
            "\n",
            "What label are you interested in? Here are the available options:\n",
            "1. Not Humanitarian\n",
            "2. Informative\n",
            "3. Not Informative\n",
            "\n",
            "Select the number corresponding to your label: 2\n",
            "\n",
            "You selected: Informative\n",
            "\n",
            "Generating summary...\n",
            "\n",
            "Summary for '2013 West Texas' and label 'Informative':\n",
            "This has been a horrible week filled with tragedy why i know its not right but ima be so angry and hateful when i see fathers hugging their daughters graduation day rt chill another explosion in texas either jesus is coming back or the government is sending a message lol no mam but i always feel nauseated every night at the same time its been like that for like 3 days its okay i can forgive you i havent seen that nigga since i was in the 10\n",
            "\n",
            "Would you like to save this summary? (yes/no): no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[df['event'].str.contains(\"mexico_earthquake\", case=False)])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWUrednjG79S",
        "outputId": "0af99ba3-d75c-4e4d-ee17-b95f20a01d6f"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        id              event     source  \\\n",
            "159     911750544728891392  mexico_earthquake  crisismmd   \n",
            "183     910547655625003009  mexico_earthquake  crisismmd   \n",
            "354     910809662383149058  mexico_earthquake  crisismmd   \n",
            "532     911640840908476416  mexico_earthquake  crisismmd   \n",
            "542     913491401320521728  mexico_earthquake  crisismmd   \n",
            "...                    ...                ...        ...   \n",
            "212586  910739720065384449  mexico_earthquake  crisismmd   \n",
            "212604  910756608371822594  mexico_earthquake  crisismmd   \n",
            "212692  910525106329329664  mexico_earthquake  crisismmd   \n",
            "212702  912398081500565508  mexico_earthquake  crisismmd   \n",
            "212734  910743867951058944  mexico_earthquake  crisismmd   \n",
            "\n",
            "                                                     text lang  lang_conf  \\\n",
            "159     RT @WingsChronicles: á¼³FDrop &amp; Donate to ...   en        NaN   \n",
            "183     What You Can Do To Help Mexico City Earthquake...   en        NaN   \n",
            "354     Rescuers struggle to save trapped girl as Mexi...   en        NaN   \n",
            "532     Aftershocks of Mexico earthquake shake members...   en        NaN   \n",
            "542     Together for Mexico: Fundraising event for Mex...   en        NaN   \n",
            "...                                                   ...  ...        ...   \n",
            "212586  [The WorldView in 5 Minutes] Earthquake in Mex...   en        NaN   \n",
            "212604  Eleven family members die during baptism in #M...   en        NaN   \n",
            "212692  Removing the jungle gym from elementary school...   en        NaN   \n",
            "212702  Drag the dog out of the ruins alive six days a...   en        NaN   \n",
            "212734  Mexico City earthquake â€“ Rescuers battle to ...   en        NaN   \n",
            "\n",
            "                      class_label  \\\n",
            "159     donation_and_volunteering   \n",
            "183     donation_and_volunteering   \n",
            "354     donation_and_volunteering   \n",
            "532              not_humanitarian   \n",
            "542              not_humanitarian   \n",
            "...                           ...   \n",
            "212586     injured_or_dead_people   \n",
            "212604     injured_or_dead_people   \n",
            "212692     injured_or_dead_people   \n",
            "212702  donation_and_volunteering   \n",
            "212734  donation_and_volunteering   \n",
            "\n",
            "                                             cleaned_text  \n",
            "159     rt fdrop amp donate to the victims of mexico e...  \n",
            "183     what you can do to help mexico city earthquake...  \n",
            "354     rescuers struggle to save trapped girl as mexi...  \n",
            "532     aftershocks of mexico earthquake shake members...  \n",
            "542     together for mexico fundraising event for mexi...  \n",
            "...                                                   ...  \n",
            "212586  the worldview in 5 minutes earthquake in mexic...  \n",
            "212604  eleven family members die during baptism in me...  \n",
            "212692  removing the jungle gym from elementary school...  \n",
            "212702  drag the dog out of the ruins alive six days a...  \n",
            "212734  mexico city earthquake rescuers battle to save...  \n",
            "\n",
            "[1836 rows x 8 columns]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}