
# Final Project: Crisis Information Retrieval and Summarization

A comprehensive, modular package for tackling the challenges of document retrieval and summarization in large-scale crisis-related datasets. This project is designed to help researchers, analysts, and organizations quickly access critical information during emergencies, enabling effective decision-making and resource allocation.

---

## **Overview**
This project implements a robust two-stage document retrieval system combined with summarization capabilities, designed to address the dual needs of accuracy and scalability when handling vast amounts of unstructured data. The solution combines traditional information retrieval techniques with modern machine learning models to provide a powerful framework for extracting and understanding relevant information.

### **Key Features**
- **Lexical Retrieval with BM25**:
  Leverages the BM25 algorithm for fast, keyword-based ranking of documents, ensuring relevant documents are surfaced quickly from large datasets.
  
- **Semantic Retrieval with FAISS and Neural Embeddings**:
  Uses FAISS (Facebook AI Similarity Search) to refine results by understanding semantic relationships between documents and user queries, offering context-aware retrieval through embeddings generated by transformer models.

- **Abstractive Summarization**:
  Generates concise and meaningful summaries of retrieved documents using state-of-the-art transformer-based summarization models. This helps users quickly grasp the essence of the information without reading through entire documents.

---

## **Installation**

### Using Poetry
```bash
poetry install
```

### Using Pip
```bash
pip install final_project
```

---

## **Features**

### **Two-Stage Document Retrieval**
- **Stage 1: BM25**  
  Ranks documents based on lexical similarity (e.g., keyword overlap).
- **Stage 2: FAISS with Neural Embeddings**  
  Refines and re-ranks results based on semantic similarity using SentenceTransformers.

### **Abstractive Summarization**
- Summarizes retrieved documents for better comprehension of large datasets.

---

## **Usage**

### **Document Retrieval**
1. Preprocess your documents using the `preprocess_documents` function.
2. Use the `TwoStagePipeline` to retrieve relevant documents.

```python
from final_project.pipeline import TwoStagePipeline

documents = ["Flooding in Texas", "Emergency response by FEMA", "Hurricane relief efforts"]
pipeline = TwoStagePipeline(documents)

results = pipeline.run("Flooding in Texas", bm25_top_k=10, faiss_top_k=5)
print(results)
```

### **Run Pipeline Script**
```bash
python run_pipeline.py
```

---

## **Documentation**
Generated using Sphinx. View it locally by opening the `index.html` file in a browser:

### MacOS/Linux:
```bash
open docs/_build/html/index.html
```

### Windows:
```cmd
start docs\_build\html\index.html
```

---

## **Project Structure**

```plaintext
.
├── data/                    # Raw and processed data files
├── docs/                    # Sphinx documentation files
├── src/                     # Source code for the application
│   ├── app/                 # Flask or FastAPI application logic
│   ├── backend/             # Core backend retrieval and summarization modules
│   └── evaluation/          # Evaluation scripts for retrieval and summarization
├── tests/                   # Unit and integration tests
├── docker/                  # Docker configuration for deployment
├── frontend/                # Frontend integration for user interaction
├── retrieval/               # Retrieval system logic
├── summarization/           # Summarization logic
├── requirements.txt         # Dependency file for pip users
├── pyproject.toml           # Poetry configuration file
└── README.md                # Project overview and usage instructions
```

---

## **Testing**

### Run Tests
Validate the system with `pytest`:
```bash
pytest tests/
```

---

## **Contributing**

1. Clone the repository:
   ```bash
   git clone <repo_url> && cd final_project
   ```
2. Install dependencies:
   ```bash
   poetry install
   ```
3. Install pre-commit hooks:
   ```bash
   pre-commit install
   ```
4. Run tests:
   ```bash
   pytest -v tests/
   ```

---

## **Virtual Environment**

This project uses a virtual environment to manage dependencies. A virtual environment ensures that all project-specific dependencies are isolated, avoiding conflicts with other Python projects on your system.

### Using Poetry
1. Install Poetry if not already installed:
   ```bash
   pip install poetry
   ```

2. Navigate to the project directory and install dependencies:
   ```bash
   poetry install
   ```

3. Activate the virtual environment:
   ```bash
   poetry shell
   ```

You’ll notice the virtual environment name (e.g., `(final-project-py3.12)`) in your terminal prompt, indicating it’s active. From here, you can run all commands like tests or scripts.

### Using Pip (Optional)
Alternatively, install dependencies directly without Poetry:
   ```bash
   pip install -r requirements.txt
   ```

---

## **Notes**
- Keep an eye on GitHub’s **green check marks** to ensure CI/CD workflows pass.
- If you make structural or dependency changes, test the system thoroughly before pushing.

---
